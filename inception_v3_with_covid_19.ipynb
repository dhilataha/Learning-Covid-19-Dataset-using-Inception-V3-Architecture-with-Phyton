{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inception-v3_with_covid-19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xEG2WeiBzJJ",
        "colab_type": "code",
        "outputId": "d61e72ab-7daa-4746-dd5f-2ecd29bd7a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knZf1zjE80O",
        "colab_type": "code",
        "outputId": "1f613e86-1124-4b2d-f391-b44e3f2d6c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd drive/'My Drive'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT1wP44kIwZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from os import listdir\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AvnLMEcJ1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 8\n",
        "default_image_size = (299, 299)\n",
        "image_size = 67\n",
        "directory_root = './covid-19/'\n",
        "width=299\n",
        "height=299\n",
        "depth=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3LMYs4KLOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            image = cv2.resize(image, default_image_size)   \n",
        "            return img_to_array(image)\n",
        "        else :\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d96W87iRKk_I",
        "colab_type": "code",
        "outputId": "7552415c-fa9a-469b-bfa0-08aa1f744f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "image_list, label_list = [], []\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir :\n",
        "        # remove .DS_Store from list\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "\n",
        "    for plant_folder in root_dir :\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list :\n",
        "            # remove .DS_Store from list\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "\n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
        "                \n",
        "            for single_plant_disease_image in plant_disease_image_list :\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "\n",
        "            for image in plant_disease_image_list[:200]:\n",
        "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True or image_directory.endswith(\".jpeg\") == True or image_directory.endswith(\".png\") == True:\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "    %time print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing normal ...\n",
            "[INFO] Processing covid ...\n",
            "[INFO] Processing covid ...\n",
            "[INFO] Processing normal ...\n",
            "[INFO] Image loading completed\n",
            "CPU times: user 91 µs, sys: 1e+03 ns, total: 92 µs\n",
            "Wall time: 97.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2qGWmaUPWjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = len(image_list)\n",
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzAyFR5WPc7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCZcC8E-PgdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6SEnOsZPkuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, \n",
        "    zoom_range=0.2,horizontal_flip=True, \n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4rFw9jy8YLK",
        "colab_type": "code",
        "outputId": "2d77e787-61fe-4d10-c10d-923a6f804cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(image_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpQLc9YpTNcb",
        "colab_type": "code",
        "outputId": "28f33744-d121-4f69-bd37-e72170bdfa69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "! pip install tensorflow==1.14"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUBBbFoDREG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = InceptionV3(weights=None, include_top=False, input_tensor=Input(shape = (width, height, depth)))\n",
        "\n",
        "x = base_model.output\n",
        "output = BatchNormalization()(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqNEG4lZRM8Z",
        "colab_type": "code",
        "outputId": "637ba5cd-f0d7-4536-f6d7-4388dd9a2e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 149, 149, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 149, 149, 32) 96          conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 149, 149, 32) 0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 147, 147, 32) 9216        activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 147, 147, 32) 96          conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 147, 147, 32) 0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 147, 147, 64) 18432       activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 147, 147, 64) 192         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 147, 147, 64) 0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 73, 73, 64)   0           activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 73, 73, 80)   240         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 73, 73, 80)   0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 71, 71, 192)  138240      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 71, 71, 192)  576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 71, 71, 192)  0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 35, 35, 192)  0           activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 35, 35, 64)   192         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 35, 35, 64)   0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 35, 35, 96)   55296       activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 35, 35, 48)   144         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 35, 35, 96)   288         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 35, 35, 48)   0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 35, 35, 96)   0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_28 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 35, 35, 64)   76800       activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 35, 35, 96)   82944       activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 35, 35, 64)   192         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 35, 35, 64)   192         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 35, 35, 96)   288         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 35, 35, 32)   96          conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 35, 35, 64)   0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 35, 35, 64)   0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 35, 35, 96)   0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 35, 35, 32)   0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_288[0][0]             \n",
            "                                                                 activation_290[0][0]             \n",
            "                                                                 activation_293[0][0]             \n",
            "                                                                 activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 35, 35, 64)   192         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 35, 35, 64)   0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 35, 35, 96)   55296       activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 35, 35, 48)   144         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 35, 35, 96)   288         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 35, 35, 48)   0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 35, 35, 96)   0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_29 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 35, 35, 64)   76800       activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 35, 35, 96)   82944       activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 35, 35, 64)   192         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 35, 35, 64)   192         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 35, 35, 96)   288         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 35, 35, 64)   192         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 35, 35, 64)   0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 35, 35, 64)   0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 35, 35, 96)   0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 35, 35, 64)   0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_295[0][0]             \n",
            "                                                                 activation_297[0][0]             \n",
            "                                                                 activation_300[0][0]             \n",
            "                                                                 activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 35, 35, 64)   192         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 35, 35, 64)   0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 35, 35, 96)   55296       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 35, 35, 48)   144         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 35, 35, 96)   288         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 35, 35, 48)   0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 35, 35, 96)   0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_30 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 35, 35, 64)   76800       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 35, 35, 96)   82944       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 35, 35, 64)   192         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 35, 35, 64)   192         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 35, 35, 96)   288         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 35, 35, 64)   192         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 35, 35, 64)   0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 35, 35, 64)   0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 35, 35, 96)   0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 35, 35, 64)   0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_302[0][0]             \n",
            "                                                                 activation_304[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "                                                                 activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 35, 35, 64)   192         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 35, 35, 64)   0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 35, 35, 96)   55296       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 35, 35, 96)   288         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 35, 35, 96)   0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 17, 17, 96)   82944       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 17, 17, 384)  1152        conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 17, 17, 96)   288         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 17, 17, 384)  0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 17, 17, 96)   0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_309[0][0]             \n",
            "                                                                 activation_312[0][0]             \n",
            "                                                                 max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 17, 17, 128)  384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 17, 17, 128)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 17, 17, 128)  114688      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 17, 17, 128)  384         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 17, 17, 128)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 17, 17, 128)  114688      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 17, 17, 128)  384         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 17, 17, 128)  384         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 17, 17, 128)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 17, 17, 128)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 17, 17, 128)  114688      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 17, 17, 128)  114688      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 17, 17, 128)  384         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 17, 17, 128)  384         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 17, 17, 128)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 17, 17, 128)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_31 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 17, 17, 192)  172032      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 17, 17, 192)  172032      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 17, 17, 192)  576         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 17, 17, 192)  576         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 17, 17, 192)  576         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 17, 17, 192)  576         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 17, 17, 192)  0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 17, 17, 192)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 17, 17, 192)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 17, 17, 192)  0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_313[0][0]             \n",
            "                                                                 activation_316[0][0]             \n",
            "                                                                 activation_321[0][0]             \n",
            "                                                                 activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 17, 17, 160)  480         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 17, 17, 160)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 17, 17, 160)  179200      activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 17, 17, 160)  480         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 17, 17, 160)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 17, 17, 160)  179200      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 17, 17, 160)  480         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 17, 17, 160)  480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 17, 17, 160)  0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 17, 17, 160)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 17, 17, 160)  179200      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 17, 17, 160)  179200      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 17, 17, 160)  480         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 17, 17, 160)  480         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 17, 17, 160)  0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 17, 17, 160)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_32 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 17, 17, 192)  215040      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 17, 17, 192)  215040      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 17, 17, 192)  576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 17, 17, 192)  576         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 17, 17, 192)  576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 17, 17, 192)  576         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 17, 17, 192)  0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 17, 17, 192)  0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 17, 17, 192)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 17, 17, 192)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_323[0][0]             \n",
            "                                                                 activation_326[0][0]             \n",
            "                                                                 activation_331[0][0]             \n",
            "                                                                 activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 17, 17, 160)  480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 17, 17, 160)  0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 17, 17, 160)  179200      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 17, 17, 160)  480         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 17, 17, 160)  0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 17, 17, 160)  179200      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 17, 17, 160)  480         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 17, 17, 160)  480         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 17, 17, 160)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 17, 17, 160)  0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 17, 17, 160)  179200      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 17, 17, 160)  179200      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 17, 17, 160)  480         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 17, 17, 160)  480         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 17, 17, 160)  0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 17, 17, 160)  0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_33 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 17, 17, 192)  215040      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 17, 17, 192)  215040      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 17, 17, 192)  576         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 17, 17, 192)  576         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 17, 17, 192)  576         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 17, 17, 192)  576         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 17, 17, 192)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 17, 17, 192)  0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 17, 17, 192)  0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 17, 17, 192)  0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_333[0][0]             \n",
            "                                                                 activation_336[0][0]             \n",
            "                                                                 activation_341[0][0]             \n",
            "                                                                 activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 17, 17, 192)  576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 17, 17, 192)  0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 17, 17, 192)  258048      activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 17, 17, 192)  576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 17, 17, 192)  0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 17, 17, 192)  258048      activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 17, 17, 192)  576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 17, 17, 192)  576         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 17, 17, 192)  0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 17, 17, 192)  0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 17, 17, 192)  258048      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 17, 17, 192)  258048      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 17, 17, 192)  576         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 17, 17, 192)  576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 17, 17, 192)  0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 17, 17, 192)  0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_34 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 17, 17, 192)  258048      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 17, 17, 192)  258048      activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 17, 17, 192)  576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 17, 17, 192)  576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 17, 17, 192)  576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 17, 17, 192)  576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 17, 17, 192)  0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 17, 17, 192)  0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 17, 17, 192)  0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 17, 17, 192)  0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_343[0][0]             \n",
            "                                                                 activation_346[0][0]             \n",
            "                                                                 activation_351[0][0]             \n",
            "                                                                 activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 17, 17, 192)  576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 17, 17, 192)  0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 17, 17, 192)  258048      activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 17, 17, 192)  576         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 17, 17, 192)  0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 17, 17, 192)  258048      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 17, 17, 192)  576         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 17, 17, 192)  576         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 17, 17, 192)  0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 17, 17, 192)  0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 8, 8, 320)    552960      activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 192)    331776      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 8, 8, 320)    960         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 8, 8, 192)    576         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 8, 8, 320)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 8, 8, 192)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_354[0][0]             \n",
            "                                                                 activation_358[0][0]             \n",
            "                                                                 max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 8, 8, 448)    1344        conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 448)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 8, 8, 384)    1548288     activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 384)    1152        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 8, 8, 384)    1152        conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 8, 8, 384)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 384)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 8, 8, 384)    442368      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 8, 8, 384)    442368      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_35 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 384)    1152        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 8, 8, 384)    1152        conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 8, 8, 384)    1152        conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 8, 8, 384)    1152        conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 8, 8, 320)    960         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 8, 8, 384)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 8, 8, 384)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 8, 8, 384)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 8, 8, 384)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 8, 8, 192)    576         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 8, 8, 320)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_361[0][0]             \n",
            "                                                                 activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 8, 8, 768)    0           activation_365[0][0]             \n",
            "                                                                 activation_366[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 8, 8, 192)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_359[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 8, 8, 448)    1344        conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 8, 8, 448)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 8, 8, 384)    1548288     activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 8, 8, 384)    1152        conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 8, 8, 384)    1152        conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 8, 8, 384)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 8, 8, 384)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 8, 8, 384)    442368      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 8, 8, 384)    442368      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_36 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 8, 8, 384)    1152        conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 8, 8, 384)    1152        conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 8, 8, 384)    1152        conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 8, 8, 384)    1152        conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 8, 8, 320)    960         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 8, 8, 384)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 8, 8, 384)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 8, 8, 384)    0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 8, 8, 384)    0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 8, 8, 192)    576         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 8, 8, 320)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_370[0][0]             \n",
            "                                                                 activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 8, 8, 768)    0           activation_374[0][0]             \n",
            "                                                                 activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 8, 8, 192)    0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_368[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_8[0][0]              \n",
            "                                                                 activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            1025        dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,901,985\n",
            "Trainable params: 23,867,553\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRMHJZyTRXkO",
        "colab_type": "code",
        "outputId": "c88b2fe7-7162-4a02-9590-1b5b7bb8017a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq3PEyx5wC41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjNFRozbfq3y",
        "colab_type": "code",
        "outputId": "b06460b3-24a7-4a34-9e1a-07101a854bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14/14 [==============================] - 125s 9s/step - loss: 8.0598 - acc: 0.4944 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 8.3987 - acc: 0.4732 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 8.1677 - acc: 0.4877 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.4454 - acc: 0.5330 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.6829 - acc: 0.4554 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 8.0694 - acc: 0.4938 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.2025 - acc: 0.4855 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - 106s 8s/step - loss: 7.9712 - acc: 0.5000 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - 105s 7s/step - loss: 7.9269 - acc: 0.5028 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.7844 - acc: 0.5117 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 8.1137 - acc: 0.4911 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.3451 - acc: 0.4765 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.1135 - acc: 0.4911 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.1137 - acc: 0.4911 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 8.3005 - acc: 0.4793 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.1137 - acc: 0.4911 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - 106s 8s/step - loss: 8.4430 - acc: 0.4704 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.2023 - acc: 0.4855 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.9269 - acc: 0.5028 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 7.8288 - acc: 0.5089 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 7.6956 - acc: 0.5173 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.3982 - acc: 0.4732 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 7.5530 - acc: 0.5262 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.8252 - acc: 0.4464 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.2562 - acc: 0.4821 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.8730 - acc: 0.5062 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 7.6956 - acc: 0.5173 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.2119 - acc: 0.4849 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 7.7401 - acc: 0.5145 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.3982 - acc: 0.4732 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.1137 - acc: 0.4911 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 7.6419 - acc: 0.5207 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.9676 - acc: 0.4375 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - 99s 7s/step - loss: 7.7399 - acc: 0.5145 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 7.5436 - acc: 0.5268 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.6838 - acc: 0.4553 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.9712 - acc: 0.5000 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 7.8730 - acc: 0.5062 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.4430 - acc: 0.4704 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - 99s 7s/step - loss: 8.0696 - acc: 0.4938 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - 103s 7s/step - loss: 8.5406 - acc: 0.4643 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - 102s 7s/step - loss: 7.6419 - acc: 0.5207 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 7.8730 - acc: 0.5062 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 8.5855 - acc: 0.4615 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - 101s 7s/step - loss: 7.6958 - acc: 0.5173 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - 99s 7s/step - loss: 8.0598 - acc: 0.4944 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 7.9172 - acc: 0.5034 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.7377 - acc: 0.4519 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.2562 - acc: 0.4821 - val_loss: 4.7827 - val_acc: 0.7000\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - 100s 7s/step - loss: 8.2562 - acc: 0.4821 - val_loss: 4.7827 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ7mvu52pD6X",
        "colab_type": "code",
        "outputId": "dbab3a37-3061-4361-c1be-0d76a1c769dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 7s 238ms/step\n",
            "Test Accuracy: 69.9999988079071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIDOD39GpTjb",
        "colab_type": "code",
        "outputId": "4cb272e1-4e9d-4d3c-b8f3-eda27657d984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noigeR4VeURTF4/w/60bwHZUc0boAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}